{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f049f05f",
   "metadata": {},
   "source": [
    "# Youtube Comments Extraction using Youtube API - Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### API configuration and creating youtube resource object\n",
    "api_key = ' ' #fill out the string with your own api_key\n",
    "\n",
    "from googleapiclient.discovery import build \n",
    "yt = build('youtube','v3',developerKey=api_key) #check out https://developers.google.com/docs/api/quickstart/python for more details\n",
    "\n",
    "### Extracting the data\n",
    "import pandas as pd\n",
    "\n",
    "ID = 'eH1fFdjzJAw' #get the id from the youtube video link\n",
    "box = [['Name', 'Comment', 'Time', 'Likes', 'Reply Count']] #we'd like to store the data in a list\n",
    "\n",
    "def scrape_comments_with_replies():\n",
    "    data = yt.commentThreads().list(part='snippet', videoId=ID, maxResults='100', textFormat=\"plainText\").execute()\n",
    "    #check out source:https://developers.google.com/youtube/v3/docs/commentThreads/list for more details\n",
    "\n",
    "    for i in data[\"items\"]:\n",
    "        # Extracting the author name\n",
    "        name = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"authorDisplayName\"]\n",
    "        # Extracting the comments\n",
    "        comment = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"textDisplay\"]\n",
    "        # Extracting the publication date\n",
    "        published_at = i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt']\n",
    "        # Extracting the total likes\n",
    "        likes = i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount']\n",
    "        # Extracting the total replies\n",
    "        replies = i[\"snippet\"]['totalReplyCount']\n",
    "        \n",
    "        # Append the data into the list\n",
    "        box.append([name, comment, published_at, likes, replies])\n",
    "\n",
    "        totalReplyCount = i[\"snippet\"]['totalReplyCount']\n",
    "        \n",
    "        # Retieve the comment replies\n",
    "        if totalReplyCount > 0:\n",
    "\n",
    "            parent = i[\"snippet\"]['topLevelComment'][\"id\"]\n",
    "\n",
    "            data2 = youtube.comments().list(part='snippet', maxResults='100', parentId=parent,\n",
    "                                            textFormat=\"plainText\").execute()\n",
    "\n",
    "            for i in data2[\"items\"]:\n",
    "                name = i[\"snippet\"][\"authorDisplayName\"]\n",
    "                comment = i[\"snippet\"][\"textDisplay\"]\n",
    "                published_at = i[\"snippet\"]['publishedAt']\n",
    "                likes = i[\"snippet\"]['likeCount']\n",
    "                replies = \"\"\n",
    "\n",
    "                box.append([name, comment, published_at, likes, replies])\n",
    "    \n",
    "    # Handling the pagination\n",
    "    # The query below retrieves the next 100 additional page of results(maxResults='100')\n",
    "    while (\"nextPageToken\" in data):\n",
    "\n",
    "        data = yt.commentThreads().list(part='snippet', videoId=ID, pageToken=data[\"nextPageToken\"],\n",
    "                                             maxResults='100', textFormat=\"plainText\").execute()\n",
    "\n",
    "        for i in data[\"items\"]:\n",
    "            name = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"authorDisplayName\"]\n",
    "            comment = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"textDisplay\"]\n",
    "            published_at = i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt']\n",
    "            likes = i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount']\n",
    "            replies = i[\"snippet\"]['totalReplyCount']\n",
    "\n",
    "            box.append([name, comment, published_at, likes, replies])\n",
    "\n",
    "            totalReplyCount = i[\"snippet\"]['totalReplyCount']\n",
    "\n",
    "            if totalReplyCount > 0:\n",
    "\n",
    "                parent = i[\"snippet\"]['topLevelComment'][\"id\"]\n",
    "\n",
    "                data2 = youtube.comments().list(part='snippet', maxResults='100', parentId=parent,\n",
    "                                                textFormat=\"plainText\").execute()\n",
    "\n",
    "                for i in data2[\"items\"]:\n",
    "                    name = i[\"snippet\"][\"authorDisplayName\"]\n",
    "                    comment = i[\"snippet\"][\"textDisplay\"]\n",
    "                    published_at = i[\"snippet\"]['publishedAt']\n",
    "                    likes = i[\"snippet\"]['likeCount']\n",
    "                    replies = ''\n",
    "\n",
    "                    box.append([name, comment, published_at, likes, replies])\n",
    "\n",
    "    # Save the retrieved data as a dataframe\n",
    "    df = pd.DataFrame({'Name': [i[0] for i in box], 'Comment': [i[1] for i in box], 'Time': [i[2] for i in box],\n",
    "                       'Likes': [i[3] for i in box], 'Reply Count': [i[4] for i in box]})\n",
    "\n",
    "    df.to_csv('youtubecommentdata.csv', index=False, header=False)\n",
    "\n",
    "    return \"Data Retrieval is Successful!\"\n",
    "\n",
    "scrape_comments_with_replies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick check the data\n",
    "data = pd.read_csv(\"youtubecommentdata.csv\",sep=',')\n",
    "data[1:10]\n",
    "print(data['Comment'][9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
